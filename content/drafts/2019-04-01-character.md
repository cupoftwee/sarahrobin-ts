---
title: "The character of a computer"
description: "Idle thoughts on the shared personhood of machines"
date: 2019-02-27 17:54:43
author: Sarah Robin
tags: ['idle-thoughts', 'HCI', 'personhood']
---

The other day, waiting for either automated tests or existential crisis to pass, I found myself thinking about how we, as humans, percieve and interact with computers. My coworker was fuming about the state of some code, and I sympathized and ended up telling him that the poor thing was trying its best, he should go easy on it. 

Which naturally caused a raised eyebrow and one of those 'uh wat' moments. I dropped it and moved on, but I still feel the same way: That program was trying its best. That's not to say its a sentient, conscious being, but frankly most life isn't, so why should we hold that against it? That computer was built and assembled to always try its absolute hardest for you. And it does. Mostly.

Some context: From an early age, I had been fascinated with computers. My elders always had words of caution when I got overly excited by some new feature or technical advance. "Garbage in, garbage out," I heard with somber nods over every holiday meal. _Computers will not save you._ Not too bad, as far as generic ominous tech advice goes. 

But, to my impressionable brain, there was a different lesson to be learned: Nomatter how frustrated I got with a computer, it was doing its best, and I had to respect and support it, like one does with everything in the world.

I mean, despite all the AI marketing fluff out there, computers (and the programs that run on them) are basically infants: incredibly dependent and very fragile, throwing tantrums or just shutting down if needs aren't met. They have very little conception of your world and context, regardless of how you simplify it for them (IE, code). They literally cannot choose to do anything but do their best to interpret whatever work you give them. 

I had to remind myself with every extension error or BSOD that they didn't know any better, and I had to understand it better to find what ailed it. And you may think its silly to train yourself to empathize with something that cannot empathize back. I understand its a strange prospect, but people hide out in bushes to watch birds hang out, and birds *really* do not give a fuck about you. I mean, they're dinosaurs, literally. Yet, every birder I've met puts personality into the birds they watch. 

Are they fools for empathizing with the literal descendents of raptors? You could say yes, but I'd say they're brilliant - the empathy isn't just for the birds, its for them, too. Those birders learn insights about avian behavior and social structures that most of us never get to see. 

That 'misplaced' empathy is a powerful cognitive tool to let you observe and infer things that most would miss. Being able to understand something's perspective unlocks so many doors - especially handy when you're debugging a program or trying to fix a computer.

So, I say, humanize your apps, your devices. Give them names. Make them yours. Understand them, take care of them. Treat them with respect and love and you might find them a bit more amiable to debug. You could call it an illusion, a hack of human instincts, but who cares? Let yourself see the personhood in things you'd assume don't have it, and you might be surprised at how satisfying caring about something can be. 
